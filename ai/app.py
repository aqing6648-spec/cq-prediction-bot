import streamlit as st
from openai import OpenAI
import os
# ================= é…ç½®åŒºåŸŸ =================
# è¿˜æ˜¯åŸæ¥çš„é…æ–¹
MY_API_KEY = st.secrets["MY_API_KEY"]
BASE_URL = "https://api.siliconflow.cn/v1"
MY_MODEL = "deepseek-ai/DeepSeek-R1-0528-Qwen3-8B"
# ===========================================

# 1. ç½‘é¡µæ ‡é¢˜è®¾ç½®
st.set_page_config(page_title="é‡åº†ä¸“å‡æœ¬AIåŠ©æ‰‹", page_icon="ğŸ“")
st.title("ğŸ“ é‡åº†ä¸“å‡æœ¬ AI å’¨è¯¢åŠ©æ‰‹")
st.caption("åŸºäº DeepSeek R1 + å†…éƒ¨ç»å¯†çŸ¥è¯†åº“")

# 2. åˆå§‹åŒ– AI å®¢æˆ·ç«¯
# ä½¿ç”¨ @st.cache_resource ç¡®ä¿æ¯æ¬¡åˆ·æ–°ç½‘é¡µä¸ç”¨é‡æ–°è¿æ¥ï¼Œæé«˜é€Ÿåº¦
@st.cache_resource
def get_client():
    return OpenAI(api_key=MY_API_KEY, base_url=BASE_URL)

client = get_client()

# 3. è¯»å–çŸ¥è¯†åº“å‡½æ•°
def get_knowledge():
    try:
        with open("knowledge.txt", "r", encoding="utf-8") as f:
            return f.read()
    except:
        return "æš‚æ— æ•°æ®"

# 4. æ ¸å¿ƒï¼šç®¡ç†èŠå¤©è®°å½• (Session State)
# Streamlit æ¯æ¬¡ä½ ç‚¹æŒ‰é’®éƒ½ä¼šé‡è·‘ä¸€éä»£ç ï¼Œæ‰€ä»¥è¦ç”¨ Session State è®°ä½ä¹‹å‰çš„èŠå¤©
if "messages" not in st.session_state:
    st.session_state.messages = []
    # å¼€åœºç™½
    st.session_state.messages.append({"role": "assistant", "content": "ä½ å¥½ï¼æˆ‘æ˜¯ä½ çš„ä¸“å±å‡å­¦é¡¾é—®ã€‚å…³äºé‡åº†ä¸“å‡æœ¬ï¼Œä½ æƒ³çŸ¥é“ä»€ä¹ˆï¼Ÿ"})

# 5. æŠŠèŠå¤©è®°å½•ç”»åœ¨ç½‘é¡µä¸Š
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.write(msg["content"])

# 6. å¤„ç†ç”¨æˆ·è¾“å…¥
# å½“ç”¨æˆ·åœ¨è¾“å…¥æ¡†å›è½¦æ—¶...
if user_input := st.chat_input("è¯·è¾“å…¥ä½ çš„é—®é¢˜ï¼ˆä¾‹å¦‚ï¼šé‡é‚®è½¯ä»¶å·¥ç¨‹å¤šå°‘åˆ†ï¼Ÿï¼‰"):
    
    # a. æ˜¾ç¤ºç”¨æˆ·çš„è¯
    with st.chat_message("user"):
        st.write(user_input)
    # b. è®°å…¥å†å²
    st.session_state.messages.append({"role": "user", "content": user_input})

    # c. å‘¼å« AI (å¸¦ RAG)
    with st.chat_message("assistant"):
        with st.spinner("AI æ­£åœ¨æŸ¥é˜…å†…éƒ¨èµ„æ–™..."):
            try:
                # æ„é€  Prompt
                context = get_knowledge()
                system_prompt = f"""
                ä½ æ˜¯ä¸€ä¸ªå‡å­¦é¡¾é—®ã€‚è¯·ä¸¥æ ¼åŸºäºä»¥ä¸‹èµ„æ–™å›ç­”ï¼š
                === èµ„æ–™ ===
                {context}
                ============
                """
                
                # å‘é€è¯·æ±‚ï¼ˆæŠŠæ‰€æœ‰å†å²è®°å½•å‘è¿‡å»ï¼Œè®©å®ƒæœ‰ä¸Šä¸‹æ–‡ï¼‰
                # è¿™é‡Œæˆ‘ä»¬åœ¨å†å²è®°å½•å‰ä¸´æ—¶æ’ä¸€ä¸ª system prompt
                messages_to_send = [{"role": "system", "content": system_prompt}] + st.session_state.messages
                
                response = client.chat.completions.create(
                    model=MY_MODEL,
                    messages=messages_to_send,
                    stream=False
                )
                
                ai_reply = response.choices[0].message.content
                st.write(ai_reply) # æŠŠå›ç­”å†™åœ¨ç½‘é¡µä¸Š
                
                # d. è®°å…¥å†å²
                st.session_state.messages.append({"role": "assistant", "content": ai_reply})
                
            except Exception as e:
                st.error(f"å‡ºé”™äº†: {e}")